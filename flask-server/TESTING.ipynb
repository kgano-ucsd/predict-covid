{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([551, 725, 3])\n",
      "torch.Size([1, 3, 256, 256])\n",
      "['COVID']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/treehax2/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/treehax2/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, models, transforms\n",
    "import dill as pickle\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from models import DenseNet121\n",
    "import joblib\n",
    "import torch.nn as nn\n",
    "from utililties import *\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "\n",
    "nrows = 256\n",
    "ncolumns = 256\n",
    "\n",
    "dbfile = open('sample.pickle', 'rb')      \n",
    "db = pickle.load(dbfile) \n",
    "\n",
    "image_path = f\"data/training/COVID/2020.01.24.919183-p27-132.png\"\n",
    "\n",
    "img = cv2.imread(image_path)\n",
    "t = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.cpu().numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "# matplotlib_imshow(t)\n",
    "\n",
    "data = torch.from_numpy(t).float()\n",
    "# print(data)\n",
    "print (data.shape)\n",
    "X = []\n",
    "if t.ndim>=3:\n",
    "    X.append(np.moveaxis(cv2.resize(t[:,:,:3], (nrows,ncolumns),interpolation=cv2.INTER_CUBIC), -1, 0))\n",
    "else:\n",
    "    smimg= cv2.cvtColor(t,cv2.COLOR_GRAY2RGB)\n",
    "    X.append(np.moveaxis(cv2.resize(smimg, (nrows,ncolumns),interpolation=cv2.INTER_CUBIC), -1, 0))\n",
    "\n",
    "x = np.array(X)\n",
    "print(torch.from_numpy(x).shape)\n",
    "\n",
    "model_main = DenseNet121(num_classes=2,pretrained=True)\n",
    "checkpoint0 = torch.load(\"Model_densenet121_state.pth\")\n",
    "model_main.load_state_dict(checkpoint0)\n",
    "\n",
    "clf = joblib.load('classifier_model.sav')\n",
    "model_main.eval()\n",
    "model_main.fc = nn.Identity()\n",
    "\n",
    "image_transforms = transforms.Compose([\n",
    "        transforms.Lambda(lambda x: x/255),\n",
    "        transforms.ToPILImage(), \n",
    "       #transforms.Resize((224, 224)),\n",
    "        transforms.Resize((230, 230)),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.45271412, 0.45271412, 0.45271412],\n",
    "                             [0.33165374, 0.33165374, 0.33165374])\n",
    "     ])\n",
    "    \n",
    "dataset = MyDataset_test(x,image_transforms)\n",
    "\n",
    "for param in model_main.parameters():\n",
    "             param.requires_grad_(False)\n",
    "\n",
    "dataloader = DataLoader(\n",
    "dataset,\n",
    "batch_size=16,\n",
    "pin_memory=True,worker_init_fn=np.random.seed(7), drop_last=False)\n",
    "\n",
    "y_pred2=[]\n",
    "for inputs in dataloader:\n",
    "    outputs = model_main(inputs)\n",
    "    preds = clf.predict(outputs)\n",
    "    \n",
    "    for ii in range(len(preds)):\n",
    "        if preds[ii] > 0.5:\n",
    "            y_pred2.append('COVID')\n",
    "        #print('covid')\n",
    "        else:\n",
    "            y_pred2.append('NonCOVID')\n",
    "        #print('noncovid')\n",
    "\n",
    "print(y_pred2)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "treehax2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e5c270835f943f205dc16370f820da5f97c4f44c99154512e57f32882d48c125"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
